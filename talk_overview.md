- Hi, who am I?
  - Student at MIT, Computer Science + considering masters in Artificial
    Intelligence
  - Love to program, check out my github
    - My website is mostly blog posts I wrote when I was in highschool, don't
      bother
  - I know Kainar from working for Locu, a company that structured data in SF
- Markov Chains: first programming project
  - Demo on some texts
- Why is this interesting?
  - Basic statistics getting closer to "language"
  - words are just arbitrary symbols. Each word could be replaced by a unique
    emoji and the code would all run the same. This should work for other
    languages (try this at home?)
- Now, project with biggest impact on my life: bookshrink
  - "Find the Essence"
  - How do you think this might work?
  - Description of how it works
    - For every word, count how many times it shows up. This is the number of points
      each word has. Don't include very common words.
    - Make Proper Nouns worth slightly more.
    - Sentence Score = (Sum of scores of words in sentence) / number of words in sentence
    - Make slightly longer sentences worth more, slightly shorter sentences worth less (fixed penalty cutoff, not sliding)

  - If you don't believe me that this works, know this:
    - Got me in to MIT
    - I've talked about this at length in every job interview I've ever had
    - Maybe 400 lines of code total, very simple idea, definitely worth

- What are some smarter techniques?
- Dimensionality Reduction: SVD, PCA, LSI, LSA

- Norms, L1 vs L2
